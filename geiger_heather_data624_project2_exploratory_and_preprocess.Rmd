---
title: pH Prediction Exploration and Transformation
author: Heather Geiger
output:
 html_document:
  smart: false
---

# Libraries

```{r, message=FALSE,warning=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
library(gridExtra)
library(VennDiagram)
```

# Exploratory analysis

## Read in data.

Read in CSV files, which are just the CSV versions of the original Excel sheets.

```{r}
training <- read.csv("pH_prediction_training_data.csv",header=TRUE,stringsAsFactors=FALSE)
test <- read.csv("pH_prediction_test_data.csv",header=TRUE,stringsAsFactors=FALSE)
```

Set aside target (PH) from training into a separate variable. Remove entirely from test.

Then, combine training and test into one data frame.

```{r}
training_target <- training$PH

training <- training[,setdiff(colnames(training),"PH")]
test <- test[,colnames(training)]

alldata <- data.frame(rbind(training,test),
    Data = rep(c("Training","Test"),times=c(nrow(training),nrow(test))),
    stringsAsFactors=FALSE)
```

## Within variables

### Unique values per variable

One useful quick thing to check can be the number and type of unique values per variable.

If for example there are only 12 unique values, and those values are 1-12, then you know that the variable may represent counts rather than a continuous numeric range.

```{r}
unique_per_var <- apply(alldata,2,function(x)length(unique(x)))
```

```{r,echo=FALSE}
print("List of number of unique values per variable:")
```

```{r}
unique_per_var[order(unique_per_var)]
```

```{r,echo=FALSE}
print("Count of unique values per variable for select variables:")
```

```{r}
vars_with_relatively_few_unique <- colnames(alldata)[order(unique_per_var)[2:6]]

apply(alldata[,vars_with_relatively_few_unique],2,function(x)table(x,useNA="ifany"))
```

Looks like brand is blank for a significant number of observations.

In Pressure.Setpoint, the vast majority of values are multiples of 2. So the ones that are between multiples (45.2, 46.4, 46.6, and 46.8) are unusual.

Similarly in Bowl.Setpoint, 122, 126, and 134 are unusual in being not multiples of 10.

### Zeros per variable

Sometimes variables will have a distribution where there are many zeros, but then the nonzero part of the distribution looks like a relatively standard continuous numeric variable.

Let's see if this is the case for any of the variables here.

```{r}
num_zeros_per_var <- rep(0,times=ncol(alldata))

for(i in 1:ncol(alldata))
{
    num_zeros_per_var[i] <- length(which(is.na(alldata[,i]) == FALSE & alldata[,i] == 0))
}

names(num_zeros_per_var) <- colnames(alldata)

num_zeros_per_var[num_zeros_per_var > 0]
```

We find the Hyd.Pressure variables have a very large number of observations equal to 0.

### Missing values

How many missing values do we find per variable?

```{r}
missing_per_var <- rep(0,times=ncol(alldata))

for(i in 1:ncol(alldata))
{
    missing_per_var[i] <- length(which(is.na(alldata[,i]) == TRUE))
}

names(missing_per_var) <- colnames(alldata)

missing_per_var[order(missing_per_var)]
```

We find most values are missing in at least a few observations. Including, brand code should maybe have some as well, once we convert the blanks to NA.

How many missing variables do we tend to find in a given observation?

```{r}
missing_per_obs <- apply(alldata,1,function(x)length(which(is.na(x) == TRUE)))

table(missing_per_obs)
```

Most observations are only missing data for at most one or two variables, which is good.

### Overall distribution of values

Let's make a simple histogram (or barplot if categorical) per variable.

```{r}
alldata$Brand.Code[alldata$Brand.Code == ""] <- "Empty"
```

```{r, fig.width=12,fig.height=24}
par(mfrow=c(8,4))

barplot(table(alldata$Brand.Code),ylab="Obs")

for(var in setdiff(colnames(alldata),c("Data","Brand.Code")))
{
    hist(alldata[,var],ylab="Obs",xlab="",main=var,labels=TRUE)
}
```

For a few of the variables that had zeros, let's also plot original histogram side-by-side with histogram of nonzero values.

Also remove the one very low outlier in Hyd.Pressure.

```{r, fig.width=12,fig.height=6}
par(mfrow=c(2,4))

var = "Balling.Lvl"

hist(alldata[,var],ylab="Obs",xlab="",main=var,labels=TRUE)
hist(alldata[alldata[,var] != 0,var],ylab="Obs",xlab="",main=paste0(var," != 0"),labels=TRUE)

for(var in c("Hyd.Pressure1","Hyd.Pressure2","Hyd.Pressure3"))
{
    hist(alldata[alldata[,var] > -40,var],ylab="Obs",xlab="",main=paste0(var," > -40"),labels=TRUE)
    hist(alldata[alldata[,var] != 0 & alldata[,var] > -40,var],ylab="Obs",xlab="",main=paste0(var," != 0, > -40"),labels=TRUE)
}
```

We see variables with various patterns including bimodal or multimodal, varying degrees of skew, and a few particular values being especially common.

Looks like for Hyd.Pressure 1,2, and 3, most values are much larger than zero if they are not exactly equal to 0.

Variables Mnf.Flow and MFR have especially strong modal peaks, and I'm curious if these are coming from any one particular value. Let's check.

```{r,echo=FALSE}
print("Top most repeated values in Mnf.Flow:")
```

```{r}
freq_per_value <- data.frame(table(alldata$Mnf.Flow))
freq_per_value$Var1 <- as.vector(freq_per_value$Var1)

freq_per_value[order(freq_per_value$Freq,decreasing=TRUE)[1:5],]
```

```{r,echo=FALSE}
print("Top most repeated values in MFR:")
```

```{r}
freq_per_value <- data.frame(table(alldata$MFR))
freq_per_value$Var1 <- as.vector(freq_per_value$Var1)

freq_per_value[order(freq_per_value$Freq,decreasing=TRUE)[1:5],]
```

Make modified histograms for these variables.

```{r,fig.width=12,fig.height=6}
par(mfrow=c(1,2))

hist(alldata$Mnf.Flow[alldata$Mnf.Flow != -100 & alldata$Mnf.Flow != -100.2 & alldata$Mnf.Flow != 0.2],
    ylab="Obs",xlab="",main="Mnf.Flow != -100.2,-100,0.2",
    labels=TRUE)

hist(alldata$MFR[alldata$MFR >= 650 & alldata$MFR <= 750],
    ylab="Obs",xlab="",main="MFR >= 650, <= 750",
    labels=TRUE)
```

These variables look more like a standard continuous numeric distribution (either normal or a bit skewed) once you remove outliers/repeated values.

## Between variables

### Co-occurence of zeros?

One quick obvious thing to check is the correlation between the different Hyd.Pressure variables.

First, do the zeros often co-occur?

```{r}
zero_hyd1 <- which(alldata[,"Hyd.Pressure1"] == 0 & is.na(alldata[,"Hyd.Pressure1"]) == FALSE)
zero_hyd2 <- which(alldata[,"Hyd.Pressure2"] == 0 & is.na(alldata[,"Hyd.Pressure2"]) == FALSE)
zero_hyd3 <- which(alldata[,"Hyd.Pressure3"] == 0 & is.na(alldata[,"Hyd.Pressure3"]) == FALSE)

list_for_venn <- list(Hyd.1 = zero_hyd1,Hyd.2 = zero_hyd2,Hyd.3 = zero_hyd3)
list_for_venn2 <- list(Hyd.1 = zero_hyd1,Hyd.3 = zero_hyd3)

object_for_venn <- venn.diagram(list_for_venn,main="Observations with var = 0",filename=NULL)
object_for_venn2 <- venn.diagram(list_for_venn2,main="Observations with var = 0",filename=NULL)

grid.draw(object_for_venn)
plot.new()
grid.draw(object_for_venn2)
```

It seems like it may be that the zeros they have in common may have a different meaning than the few cases where they are not in common, for Hyd.Pressure1.

Make a quick histogram/table of values near 0 for these variables, which may confirm this idea.

```{r}
var = "Hyd.Pressure1"

hist(alldata[alldata[,var] > -40 & alldata[,var] != 0 & alldata[,var] < 5,var],
    ylab="Obs",xlab="",main=paste0(var,", > -40, < 5, != 0"),
    labels=TRUE)
```

```{r}
for(var in c("Hyd.Pressure2","Hyd.Pressure3"))
{
    print(paste0(var,", table for >-40, < 5, != 0"))
    print(table(alldata[alldata[,var] > -40 & alldata[,var] != 0 & alldata[,var] < 5,var]))
}
```

It seems like it would fit well for Hyd.Pressure1 to take the zeros not found in Hyd.Pressure2 or Hyd.Pressure3 as true zeros.

### Correlations between certain specific variables

Next, make scatterplots looking at correlation including nonzero values for Hyd.Pressure 1-4.

```{r,fig.width=12,fig.height=12}
pairs(alldata[alldata[,"Hyd.Pressure1"] > -40,paste0("Hyd.Pressure",1:4)],lower.panel=NULL,main="Minus 1/2/3 < -40 observation")
```

Other than the common zeros, the Hyd.Pressure variables do not have a lot in common.

Some correlation between 2 and 3, but it is not that strong other than when both are very low.

### Correlations between all predictors

Now, time to take an unbiased look and see which variables are most correlated.
